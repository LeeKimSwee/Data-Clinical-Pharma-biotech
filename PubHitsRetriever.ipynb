{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import a txt file and transform if as a list. Note here new line separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('path', \"r\")\n",
    "mylist = file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program to submit a list of input search to pubmed and output data frame with input and search term "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           term  hits\n",
      "0          Swee  1073\n",
      "1       Swee lk    15\n",
      "2  Lee Kim Swee    14\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "import urllib.request\n",
    "# requires urllib to get webpage info\n",
    "import re\n",
    "# requires re to locate number of hits in source code\n",
    "import pandas as pd\n",
    "# requires pandas to output data frame\n",
    "\n",
    "searchlist = ['Swee','Swee lk','Lee Kim Swee']\n",
    "# define a search list\n",
    "url = 'https://www.ncbi.nlm.nih.gov/pubmed/?'\n",
    "# open pubmed website with ? for request\n",
    "df = pd.DataFrame()\n",
    "# create empty data frame\n",
    "for i in searchlist:\n",
    "    data = {'term':str(i)}\n",
    "    values = urllib.parse.urlencode(data)\n",
    "    req = url + values\n",
    "    resp = urllib.request.urlopen(req)\n",
    "    # open page for each request\n",
    "    x = resp.read()\n",
    "    text = x.decode('utf-8')\n",
    "    # transform page into object to pass to re\n",
    "    number = re.search(r'id=\"resultcount\" value=\"(.*)\" /><input name', text)  \n",
    "    hits = number.group(1)\n",
    "    # having identified strings that precedes and follow relevant info, retrieve it using re.search\n",
    "    # then output group with index = 1 \n",
    "    df = df.append({'term':str(i), 'hits': hits}, ignore_index=True)\n",
    "    #append to the dataFrame and print\n",
    "df = df[['term','hits']]\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       term   hits\n",
      "0     T reg   1630\n",
      "1      ILC3    132\n",
      "2  BioMed X  11852\n"
     ]
    }
   ],
   "source": [
    "df = df[['term','hits']]\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save file to current work directory using .to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('test170201.txt', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
